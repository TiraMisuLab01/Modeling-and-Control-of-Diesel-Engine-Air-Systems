Here is the `task6_readme.md` file content, written in the requested academic format with Chinese translations.

* * *

Task 6: State Regulation and Optimization Report
================================================

## Introduction

The primary objective of Task 6 is to investigate the direct regulation of the system's four internal state variables, rather than solely controlling the outputs. Specifically, the goal is to maintain the state vector $x$ at a specific steady-state setpoint $x_{sp} = [0, 0.5, -0.4, 0.3]^T$. This presents a more challenging scenario than output regulation because the number of state variables (four) exceeds the number of control inputs (two), leading to an overdetermined system in terms of equilibrium constraints. Consequently, the task requires a rigorous feasibility analysis to determine if the target state is physically attainable. Upon confirming that the exact target is unreachable due to the system's physical structure, the problem transforms into an optimization challenge. The aim shifts to finding the optimal reachable steady state $x_s^*$ that minimizes a weighted quadratic cost function $J(x_s)$, balancing the errors between different states according to their importance derived from the matriculation number parameters.

> 任务6的主要目标是研究系统四个内部状态变量的直接调节，而不仅仅是控制输出。具体而言，目标是将状态向量 $x$ 维持在特定的稳态设定点 $x_{sp} = [0, 0.5, -0.4, 0.3]^T$。这比输出调节更具挑战性，因为状态变量的数量（4个）超过了控制输入的数量（2个），导致在平衡约束方面出现超定系统。因此，该任务需要进行严格的可行性分析，以确定目标状态在物理上是否可达。在确认由于系统的物理结构导致无法精确达到目标后，该问题转化为一个优化挑战。目标转变为寻找最优的可达稳态 $x_s^*$，使其最小化加权二次代价函数 $J(x_s)$，根据学号参数导出的重要性来权衡不同状态之间的误差。

## Tasks Solvement



The solution strategy begins with a fundamental analysis of the system's equilibrium points based on the linear system theory presented in **Chapter 7**. For a linear time-invariant system described by $\dot{x} = Ax + Bu$, a steady state implies that the rate of change of the state vector is zero. Therefore, to maintain the system at the target setpoint $x_{sp}$, there must exist a constant control input $u_{ss}$ that satisfies the equilibrium equation $0 = A x_{sp} + B u_{ss}$. This can be rearranged into a linear algebraic form $B u_{ss} = -A x_{sp}$. Using MATLAB, we analyzed the rank of the control input matrix $B$ and the augmented matrix $[B, -A x_{sp}]$. The results indicated that while the rank of $B$ is 2, the rank of the augmented matrix is 3. According to the Rouché–Capelli theorem, this discrepancy confirms that the target vector $-A x_{sp}$ does not lie within the column space of $B$, rendering the exact regulation to $x_{sp}$ theoretically infeasible1.

> 解决策略首先基于**第7章**中介绍的线性系统理论，对系统的平衡点进行基础分析。对于由 $\dot{x} = Ax + Bu$ 描述的线性时不变系统，稳态意味着状态向量的变化率为零。因此，为了将系统维持在目标设定点 $x_{sp}$，必须存在满足平衡方程 $0 = A x_{sp} + B u_{ss}$ 的恒定控制输入 $u_{ss}$。这可以重排为线性代数形式 $B u_{ss} = -A x_{sp}$。利用 MATLAB，我们分析了控制输入矩阵 $B$ 和增广矩阵 $[B, -A x_{sp}]$ 的秩。结果表明，虽然 $B$ 的秩为 2，但增广矩阵的秩为 3。根据鲁谢-卡佩利定理（Rouché–Capelli theorem），这一差异证实了目标向量 $-A x_{sp}$ 不在 $B$ 的列空间内，使得精确调节到 $x_{sp}$ 在理论上不可行 2。

Given the infeasibility of the original target, we formulated a constrained optimization problem to find the best achievable steady state. We defined a cost function $J(x_s) = \frac{1}{2}(x_s - x_{sp})^T W (x_s - x_{sp})$, where $W$ is a diagonal weight matrix derived from the student ID parameters ($a=8, b=4, c=0, d=1$), resulting in $W = \text{diag}(9, 5, 1, 2)$. This formulation draws parallels to the **Quadratic Optimal Control (LQR)** concepts discussed in **Chapter 8**, where a weighted quadratic form is used to penalize deviations3. To solve this, we derived the mapping between steady-state input and state using the relationship $x_s = -A^{-1}B u_s$, denoting $M = -A^{-1}B$. Substituting this into the cost function transforms the problem into an unconstrained minimization with respect to the input $u_s$. By setting the gradient of the objective function to zero, we derived the analytical solution for the optimal steady-state input as $u_s^* = (M^T W M)^{-1} M^T W x_{sp}$. Using MATLAB matrix operations, the optimal steady state $x_s^*$ was calculated, resulting in a minimum cost value of approximately $0.218$. The numerical results showed that states with higher weights (e.g., $x_1$ with weight 9) converged very close to the target, while states with lower weights (e.g., $x_3$ with weight 1) exhibited larger deviations, validating the optimization logic.

> 鉴于原始目标不可行，我们制定了一个约束优化问题来寻找最佳可达稳态。我们定义了代价函数 $J(x_s) = \frac{1}{2}(x_s - x_{sp})^T W (x_s - x_{sp})$，其中 $W$ 是根据学号参数 ($a=8, b=4, c=0, d=1$) 导出的对角权重矩阵，结果为 $W = \text{diag}(9, 5, 1, 2)$。该公式与**第8章**中讨论的**二次最优控制 (LQR)** 概念相似，即使用加权二次型来惩罚偏差 4。为了解决这个问题，我们利用关系式 $x_s = -A^{-1}B u_s$ 推导了稳态输入与状态之间的映射，令 $M = -A^{-1}B$。将其代入代价函数，问题转化为关于输入 $u_s$ 的无约束最小化问题。通过令目标函数的梯度为零，我们推导出了最优稳态输入的解析解 $u_s^* = (M^T W M)^{-1} M^T W x_{sp}$。利用 MATLAB 矩阵运算，计算出最优稳态 $x_s^*$，最小代价约为 $0.218$。数值结果表明，权重较高的状态（如权重为 9 的 $x_1$）收敛得非常接近目标，而权重较低的状态（如权重为 1 的 $x_3$）表现出较大的偏差，验证了优化逻辑。

To implement the control strategy, we designed a controller that ensures asymptotic convergence to the calculated optimal steady state $x_s^*$. The control structure integrates a feedforward component for equilibrium maintenance and a feedback component for stabilization, conceptually aligned with the servo control principles in **Chapter 9**5. The control law is defined as $u(t) = u_s^* - K(x(t) - x_s^*)$, where $u_s^*$ provides the necessary energy to maintain the optimal steady state, and the feedback gain $K$ stabilizes the error dynamics. The gain matrix $K$ was calculated using the LQR method to ensure robust transient performance. Simulation results demonstrated that starting from the initial condition $x_0$, the state trajectories smoothly converged to and settled exactly at $x_s^*$, and the control inputs stabilized at $u_s^*$. This confirms that the combination of static optimization and dynamic feedback control effectively regulates the system to the best possible operating point under physical constraints.

> 为了实施控制策略，我们设计了一个控制器，以确保渐近收敛到计算出的最优稳态 $x_s^*$。该控制结构集成了用于维持平衡的前馈分量和用于稳定的反馈分量，在概念上与**第9章**中的伺服控制原理一致 6。控制律定义为 $u(t) = u_s^* - K(x(t) - x_s^*)$，其中 $u_s^*$ 提供维持最优稳态所需的能量，反馈增益 $K$ 用于稳定误差动态。增益矩阵 $K$ 使用 LQR 方法计算，以确保鲁棒的瞬态性能。仿真结果表明，从初始条件 $x_0$ 开始，状态轨迹平滑收敛并精确稳定在 $x_s^*$，控制输入稳定在 $u_s^*$。这证实了静态优化与动态反馈控制的结合，有效地将系统调节到了物理约束下的最佳工作点。

## Discussion and Conclusion

Task 6 provided a comprehensive synthesis of linear system theory, bridging the gap between theoretical feasibility analysis and practical control implementation. The impossibility of meeting the original setpoint highlighted a critical engineering reality: actuators often have limited degrees of freedom compared to the system's complexity (number of states). The optimization process successfully demonstrated how weighting matrices can be strategically used to prioritize critical performance variables when trade-offs are inevitable. Specifically, the high accuracy achieved for state $x_1$ versus the larger error accepted for $x_3$ perfectly illustrated the "optimization under constraints" paradigm. Furthermore, the successful stabilization at the calculated optimal point validated the effectiveness of combining steady-state feedforward control with optimal state feedback.

> 任务6提供了线性系统理论的综合应用，弥合了理论可行性分析与实际控制实施之间的差距。无法满足原始设定点这一事实凸显了一个关键的工程现实：与系统的复杂性（状态数量）相比，执行器通常具有有限的自由度。优化过程成功展示了在不可避免的权衡中，如何策略性地使用权重矩阵来优先考虑关键的性能变量。具体而言，状态 $x_1$ 实现的高精度与 $x_3$ 接受的较大误差完美诠释了“约束下的优化”范式。此外，在计算出的最优点的成功稳定，验证了结合稳态前馈控制与最优状态反馈的有效性。

This concludes the entire mini-project. Through the six tasks, we have systematically explored pole placement, LQR, observer design, decoupling, servo control, and state regulation. Each task built upon the previous theories, culminating in this final optimization problem that required a holistic understanding of system dynamics, controllability, and steady-state analysis. The simulation results across all tasks confirm the correctness of the derived models and control laws, fulfilling all project requirements.

> 整个 Mini-project 到此结束。通过这六个任务，我们系统地探索了极点配置、LQR、观测器设计、解耦、伺服控制和状态调节。每个任务都建立在之前的理论基础之上，最终汇聚成这个需要对系统动力学、可控性和稳态分析有整体理解的优化问题。所有任务的仿真结果证实了推导模型和控制律的正确性，满足了所有项目要求。
